{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4f6ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78244d36",
   "metadata": {},
   "source": [
    "### 1. Write a function to generate a data matrix X. \n",
    "**Inputs**: Number of samples, feature dimension. \n",
    "\n",
    "**Output**: Data matrix X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dab5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_generator(sample_count, feature_dimension):\n",
    "    matrix = np.random.randint(100, size=(sample_count, feature_dimension))\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68281a11",
   "metadata": {},
   "source": [
    "### 2. Write a function to generated dependent variable column t. \n",
    "**Inputs**: Data matrix X, weight vector for each column, bias w0, noise variance\n",
    "\n",
    "**Output**: Target vector t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0af466a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_generator(matrix, weight_vector, bais_w_0, noise_variance):\n",
    "    noise=np.random.normal(loc=0, scale= noise_variance, size= weight_vector.shape)\n",
    "#   weight_vector_transpose = weight_vector.transpose() \n",
    "    xw = np.dot( matrix, weight_vector ) # matrix multiplication\n",
    "    return xw + bais_w_0 + noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89eb281",
   "metadata": {},
   "source": [
    "### 3. Write a function to compute a linear regression estimate. \n",
    "\n",
    "**Input**: data matrix X and weight vector w\n",
    "\n",
    "**Output**: y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "279b079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_estimate_y(matrix, weight_vector):\n",
    "    return np.dot( matrix, weight_vector ) # matrix multiplication "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566e4766",
   "metadata": {},
   "source": [
    "### 4. Write a function to compute the mean square error of two vectors y and t.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b715996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(estimate_y, target_y):\n",
    "    return (np.square(estimate_y - target_y)).mean(axis=0)[0] \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d13f76",
   "metadata": {},
   "source": [
    "### 5. Write a function to estimate the weights of linear regression using pseudo-inverse, assuming L2 regularization \n",
    "**Input**: X, t, and lambda\n",
    "\n",
    "**Output**: w, MSE, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d5117af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_weight(matrix, target_y , lambda_l2):\n",
    "    transpose_matrix = matrix.transpose()\n",
    "    matrix_multiplication = np.dot(transpose_matrix , matrix)\n",
    "    identity_size = lambda_l2*np.identity(matrix_multiplication.shape[0])\n",
    "    add_matrix = identity_size + matrix_multiplication\n",
    "    add_matrix_inverse = np.linalg.inv(add_matrix)\n",
    "    matrix_multiplication_target_y = np.dot(transpose_matrix, target_y)\n",
    "    weight = np.dot(add_matrix_inverse , matrix_multiplication_target_y)\n",
    "    pridicted_y = np.dot(matrix, weight)\n",
    "    MSE= mean_square_error(pridicted_y, target_y)\n",
    "    return weight, MSE, pridicted_y                                     #return as tuple  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b91470",
   "metadata": {},
   "source": [
    "### 6. Write a function to compute the gradient of MSE with respect to its weight vector. \n",
    "**Input**: X matrix, t vector, and w vector\n",
    "\n",
    "**Output**: gradient vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5e3723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  compute_gradient_of_MSE(matrix, t_vector, w_vector):\n",
    "    x_t=matrix.transpose()\n",
    "    return 2*np.dot(np.dot(x_t, matrix), w_vector) - 2*np.dot(x_t, t_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d2bc8",
   "metadata": {},
   "source": [
    "### 7. Write a function to compute L2 norm of a vector w passed as a numpy array. Exclude bias w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab234a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_norm(weight_vector):\n",
    "    return np.linalg.norm(weight_vector, ord=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515d11c2",
   "metadata": {},
   "source": [
    "### 8. Write a function to compute the gradient of L2 norm with respect to the weight vectors.\n",
    "\n",
    "**Input**: X matrix and w vector\n",
    "\n",
    "**Output**: gradient vector, where gradient with respect to w0 is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "573dfbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  compute_gradient_of_L2_norm(matrix, vector_w):\n",
    "    return vector_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c775c8",
   "metadata": {},
   "source": [
    "### 9. Write a function to compute L1 norm of a vector w passed as a numpy array. Exclude bias w0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bddb6263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l1_norm(weight_vector):\n",
    "    return np.linalg.norm(weight_vector, ord=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7722231",
   "metadata": {},
   "source": [
    "### 10. Write a function to compute the gradient of L1 norm with respect to the weight vectors. \n",
    "\n",
    "a) ***Input***: X matrix and w vector\n",
    "\n",
    "b) ***Output***: gradient vector, where gradient with respect to w0 is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "043eaff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  compute_gradient_of_L1_norm(matrix, vector_w):\n",
    "    l =[1]*vector_w.shape[0]\n",
    "    return np.array(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735f116",
   "metadata": {},
   "source": [
    "### 11. Write a function for a single update of weights of linear regression using gradient descent. \n",
    "a) **Input**: X, t, w, eta, lambda 2, lambda 1. Note that the weight of MSE will be 1\n",
    "\n",
    "b) **Output**: updated weight and updated MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a52fc94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_update_weight(X, t, w, eta, lambda_1, lambda_2):\n",
    "    gradient_mse = compute_gradient_of_MSE(X, t, w)\n",
    "    updated_weight = w - eta * gradient_mse\n",
    "    new_predicted_y = np.dot(X, updated_weight)\n",
    "    updated_mse = mean_square_error(new_predicted_y, t)\n",
    "    return updated_weight, updated_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f3f536",
   "metadata": {},
   "source": [
    "### 12. Write a function to estimate the weights of linear regression using gradient descent.\n",
    "\n",
    "a) **Inputs**: X, t, lambda2 (default 0), lambda1 (default 0), eta, max_iter, min_change_NRMSE\n",
    "\n",
    "b) **Output**: Final w, final RMSE normalized with respect to variance of t.\n",
    "\n",
    "c) **Stopping criteria**: Either max_iter has been reached, or the normalized RMSE does not change by more than\n",
    "min_change_NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df482235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_weight_gradient_descent(X, t, eta, max_iter, min_change_NRMSE, lambda2=0, lambda1=0):\n",
    "    weight, MSE, pridicted_y = estimate_weight(X, t, lambda2)\n",
    "    for i in range(max_iter):\n",
    "        updated_weight, updated_mse = single_update_weight(X, t, weight, eta, lambda1, lambda2)\n",
    "        nrmse = np.sqrt(updated_mse) / np.mean(t)\n",
    "        if nrmse < min_change_NRMSE:\n",
    "            break\n",
    "    return updated_weight, nrmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfed5d",
   "metadata": {},
   "source": [
    "### 13. Run multiple experiments (with different random seeds) for, plot the results of (box plots), and comment on the trends and potential reasons for the following relations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6aa2dc",
   "metadata": {},
   "source": [
    "a) Training and validation NRMSE obtained using pseudo inverse with number of training samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c933fa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (100,) (15,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11792/2829537370.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mbias_w_0\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfeaturs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mnoise_varience\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtarget_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbias_w_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_varience\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mtarget_training_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtraining_count\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtarget_validation_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_sample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_count\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11792/2544943148.py\u001b[0m in \u001b[0;36mcolumn_generator\u001b[1;34m(matrix, weight_vector, bais_w_0, noise_variance)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#   weight_vector_transpose = weight_vector.transpose()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mxw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_vector\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m# matrix multiplication\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mxw\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbais_w_0\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (100,) (15,) "
     ]
    }
   ],
   "source": [
    "\n",
    "# Creating dataset\n",
    "sample_count = 100\n",
    "training_validation_ratio = .8\n",
    "featurs = 15\n",
    "eta= 1\n",
    "max_iter = 20\n",
    "min_change_NRMSE  = 99999\n",
    "lambda2 = 0\n",
    "lambda1 = 0\n",
    "nrmse_list=[]\n",
    "for i in range(10):\n",
    "    training_count = int(sample_count*training_validation_ratio)\n",
    "    sample = matrix_generator(sample_count, featurs)\n",
    "    training_sample = sample[0:training_count]\n",
    "    validation_sample = sample[training_count:]\n",
    "    weight_vector = np.array([1]*featurs)\n",
    "    bias_w_0= np.array([0]*sample_count)\n",
    "    noise_varience =  0.1\n",
    "    target_sample = column_generator(sample, weight_vector,bias_w_0, noise_varience)\n",
    "    target_training_sample = target_sample[0:training_count]\n",
    "    target_validation_sample = target_sample[training_count:]\n",
    "    updated_weight, updated_nrmse = estimate_weight_gradient_descent(training_sample, target_training_sample, eta, max_iter, min_change_NRMSE, lambda2=0, lambda1=0)\n",
    "    nrmse_list.append(updated_nrmse)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "plt.boxplot(nrmse_list)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c5ffd7",
   "metadata": {},
   "source": [
    "\n",
    "b) Training and validation NRMSE obtained using pseudo inverse with number of variables \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442cce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating dataset\n",
    "sample_count = 100\n",
    "training_validation_ratio = .8\n",
    "featurs = 15\n",
    "eta= 1\n",
    "max_iter = 20\n",
    "min_change_NRMSE  = 99999\n",
    "lambda2 = 0\n",
    "lambda1 = 0\n",
    "nrmse_list=[]\n",
    "for i in range(10):\n",
    "    training_count = int(sample_count*training_validation_ratio)\n",
    "    sample = matrix_generator(sample_count, featurs)\n",
    "    training_sample = sample[0:training_count]\n",
    "    validation_sample = sample[training_count:]\n",
    "    weight_vector = np.array([1]*featurs)\n",
    "    bias_w_0= np.array([0]*sample_count)\n",
    "    noise_varience =  np.random.random()*10\n",
    "    target_sample = column_generator(sample, weight_vector,bias_w_0, noise_varience)\n",
    "    target_training_sample = target_sample[0:training_count]\n",
    "    target_validation_sample = target_sample[training_count:]\n",
    "    updated_weight, updated_nrmse = estimate_weight_gradient_descent(training_sample, target_training_sample, eta, max_iter, min_change_NRMSE, lambda2=0, lambda1=0)\n",
    "    nrmse_list.append(updated_nrmse)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "plt.boxplot(nrmse_list)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede25bd3",
   "metadata": {},
   "source": [
    "c) Training and validation NRMSE obtained using pseudo inverse with noise variance [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating dataset\n",
    "sample_count = 100\n",
    "training_validation_ratio = .8\n",
    "featurs = 15\n",
    "eta= 1\n",
    "max_iter = 20\n",
    "min_change_NRMSE  = 99999\n",
    "lambda2 = 0\n",
    "lambda1 = 0\n",
    "nrmse_list=[]\n",
    "for i in range(10):\n",
    "    training_count = int(sample_count*training_validation_ratio)\n",
    "    sample = matrix_generator(sample_count, featurs)\n",
    "    training_sample = sample[0:training_count]\n",
    "    validation_sample = sample[training_count:]\n",
    "    weight_vector = np.array([1]*featurs)\n",
    "    bias_w_0= np.array([0]*sample_count)\n",
    "    noise_varience =  np.random.random()*10\n",
    "    target_sample = column_generator(sample, weight_vector,bias_w_0, noise_varience)\n",
    "    target_training_sample = target_sample[0:training_count]\n",
    "    target_validation_sample = target_sample[training_count:]\n",
    "    updated_weight, updated_nrmse = estimate_weight_gradient_descent(training_sample, target_training_sample, eta, max_iter, min_change_NRMSE, lambda2=0, lambda1=0)\n",
    "    nrmse_list.append(updated_nrmse)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "plt.boxplot(nrmse_list)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f15dd35",
   "metadata": {},
   "source": [
    "d) Training and validation NRMSE obtained using pseudo inverse with w0 [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f935eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating dataset\n",
    "sample_count = 100\n",
    "training_validation_ratio = .8\n",
    "featurs = 15\n",
    "eta= 1\n",
    "max_iter = 20\n",
    "min_change_NRMSE  = 99999\n",
    "lambda2 = 0\n",
    "lambda1 = 0\n",
    "nrmse_list=[]\n",
    "for i in range(10):\n",
    "    training_count = int(sample_count*training_validation_ratio)\n",
    "    sample = matrix_generator(sample_count, featurs)\n",
    "    training_sample = sample[0:training_count]\n",
    "    validation_sample = sample[training_count:]\n",
    "    weight_vector = np.array([1]*featurs)\n",
    "    bias_w_0= np.array([0]*sample_count)\n",
    "    noise_varience =  np.random.random()*10\n",
    "    target_sample = column_generator(sample, weight_vector,bias_w_0, noise_varience)\n",
    "    target_training_sample = target_sample[0:training_count]\n",
    "    target_validation_sample = target_sample[training_count:]\n",
    "    updated_weight, updated_nrmse = estimate_weight_gradient_descent(training_sample, target_training_sample, eta, max_iter, min_change_NRMSE, lambda2=0, lambda1=0)\n",
    "    nrmse_list.append(updated_nrmse)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "plt.boxplot(nrmse_list)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55619f32",
   "metadata": {},
   "source": [
    "e) Training and validation NRMSE obtained using pseudo inverse with lambda2 [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50731483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating dataset\n",
    "sample_count = 100\n",
    "training_validation_ratio = .8\n",
    "featurs = 15\n",
    "eta= 1\n",
    "max_iter = 20\n",
    "min_change_NRMSE  = 99999\n",
    "lambda2 = 0\n",
    "lambda1 = 0\n",
    "nrmse_list=[]\n",
    "for i in range(10):\n",
    "    training_count = int(sample_count*training_validation_ratio)\n",
    "    sample = matrix_generator(sample_count, featurs)\n",
    "    training_sample = sample[0:training_count]\n",
    "    validation_sample = sample[training_count:]\n",
    "    weight_vector = np.array([1]*featurs)\n",
    "    bias_w_0= np.array([0]*sample_count)\n",
    "    noise_varience =  np.random.random()*10\n",
    "    target_sample = column_generator(sample, weight_vector,bias_w_0, noise_varience)\n",
    "    target_training_sample = target_sample[0:training_count]\n",
    "    target_validation_sample = target_sample[training_count:]\n",
    "    updated_weight, updated_nrmse = estimate_weight_gradient_descent(training_sample, target_training_sample, eta, max_iter, min_change_NRMSE, lambda2=0, lambda1=0)\n",
    "    nrmse_list.append(updated_nrmse)\n",
    "\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    " \n",
    "plt.boxplot(nrmse_list)\n",
    "\n",
    "# show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f419f",
   "metadata": {},
   "source": [
    "f) Time taken to solve pseudo inverse with number of samples and its breaking point [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555d977b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "976b3f80",
   "metadata": {},
   "source": [
    "g) Time taken to solve pseudo inverse with number of variables and its breaking point [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf1fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdcbe3ff",
   "metadata": {},
   "source": [
    "h) Training and validation NRMSE obtained using gradient descent with max_iter [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bec7cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43a9dd6b",
   "metadata": {},
   "source": [
    "i) Training and validation NRMSE obtained using gradient descent with eta [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7264d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f5e4c8c",
   "metadata": {},
   "source": [
    "j) Time taken to solve gradient descent with number of samples and its breaking point [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba5515e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b60f3af",
   "metadata": {},
   "source": [
    "k) Time taken to solve gradient descent with number of variables and its breaking point [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410792d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a35908d1",
   "metadata": {},
   "source": [
    "l) Training and validation NRMSE and number of nearly zero weights obtained using gradient descent with lambda2 [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc8e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa6f6326",
   "metadata": {},
   "source": [
    "m) Training and validation NRMSE and number of nearly zero weights obtained using gradient descent with lambda1 [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf9d792",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "872f021a",
   "metadata": {},
   "source": [
    "n) Experiment (h) but, this time with number of training samples [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc17b197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff63a13d",
   "metadata": {},
   "source": [
    "o) Experiment (h) but, this time with number of variables [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dbe63b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26493923",
   "metadata": {},
   "source": [
    "### Testing Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7fbf88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROW = 3\n",
    "COLUMN = 5\n",
    "matrix = matrix_generator(ROW,COLUMN)\n",
    "weight_vector = matrix_generator(COLUMN, 1)\n",
    "noise_variance = matrix_generator(ROW, 1)\n",
    "bais_w_0 = matrix_generator(ROW, 1)\n",
    "target_y = column_generator(matrix, weight_vector, bais_w_0, noise_variance)\n",
    "estimate_y=calculate_estimate_y(matrix, weight_vector)\n",
    "mse=mean_square_error(estimate_y, target_y)\n",
    "l2_norm=compute_l2_norm(weight_vector)\n",
    "weight, MSE, pridicted_y =estimate_weight(matrix,target_y,l2_norm)\n",
    "gradient_weight = compute_gradient_of_MSE(matrix, target_y, weight)\n",
    "cg_l2 = compute_gradient_of_L2_norm(matrix, weight_vector)\n",
    "cg_l1 = compute_gradient_of_L1_norm(matrix, weight_vector)\n",
    "single_update_weight(matrix, target_y, weight_vector, 1 , 0, 0)\n",
    "wgd = estimate_weight_gradient_descent(matrix, target_y, 1, 10, 50, lambda2=0, lambda1=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bc54e",
   "metadata": {},
   "source": [
    "14. Write your overall learning points by doing entire assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e596ce",
   "metadata": {},
   "source": [
    "This assignment helps me to learn about python and numpy. how to implement linear regression using python. I came across about differnt Python's Library and their"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f65118",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
